# Branch Office Telemetry Dashboard (Splunk Dashboard Studio)

This dashboard was created for two specific purposes:

## 1. Telemetry Verification
To confirm that all synthetic branch-office data sources (heartbeat, HTTP access logs, and SMB activity) are being generated correctly on the ThinkPad “branch office” node, forwarded by the Universal Forwarder, and successfully ingested into the branch_office index in Splunk.  
It also serves as a quick future health-check to verify that branch-office telemetry is still arriving as expected if issues ever occur.

## 2. First Dashboard Build / Functional Test
To practise building a dashboard in Splunk Dashboard Studio using real ingested data, validate the end-to-end log flow, and ensure each panel updates correctly.  
This is not a security dashboard — the data is mostly synthetic and the visualisation is intentionally simple. Its role is to verify the pipeline, not to detect threats.

---

## Branch Office Telemetry – Data Sources (Cron Jobs)

The ThinkPad acting as a “branch office” currently generates three synthetic telemetry streams via cron jobs:

- **Heartbeat:**  
  A script writes a one-line “Branch Office heartbeat OK” entry every minute into /var/log/cyberlab/branch-heartbeat.log.

- **HTTP Access:**  
  A cron job triggers two HTTP requests per minute (/ and /no-such-page) to generate predictable entries in the NGINX access log.

- **SMB Activity:**  
  A small write/read test runs every minute against the Samba share to ensure SMB log entries are continuously produced.

These synthetic events exist purely to populate Splunk and allow the first dashboard to be built and tested.

---

## Screenshot

![Splunk Dashboard](../../assets/splunk_dashboard_branch_office.png)

---

# Dashboard Panels

Each panel on this dashboard visualises one branch-office telemetry source.  
The searches are intentionally simple and use synthetic data generated by the cron jobs on the ThinkPad node.

---

## 1. Branch Heartbeat (1-Minute Interval) — *Visualization: Line Chart*

### SPL Used:
```bash
index=branch_office sourcetype=branch_heartbeat  
| timechart span=1m count
```

```index=branch_office``` - Search only within the branch_office index  
```sourcetype=branch_heartbeat``` - Filter to heartbeat events generated by the cron job  
```| timechart …``` - Convert events into a time-series chart  
```span=1m``` - Bucket events into 1-minute intervals — matches the cron schedule  
```count``` - Count how many heartbeat events occurred each minute  

### Purpose:
Displays one event per minute if the branch node, cron job, UF forwarding, and ingestion pipeline are all working.  
Gaps immediately reveal forwarding issues, machine sleep/offline periods, cron failures, or timestamp problems.

---

## 2. SMB Activity (1-Minute Interval) — *Visualization: Line Chart*

### SPL Used:
```bash
index=branch_office sourcetype=smb_activity  
| timechart span=1m count
```
This search is identical in structure to the Branch Heartbeat panel.  
The only difference is:  
```sourcetype=smb_activity``` - Reads from the SMB activity log written into /srv/samba/share/smb_activity.log every minute.

### Purpose:
Shows regular write activity to the Samba share from the ThinkPad.  
If the panel flatlines, it indicates issues with the cron script writing the SMB log, the SMB share itself, file permissions, the Universal Forwarder’s monitor stanza or Splunk ingestion.  
This panel verifies that the SMB share is alive, writable, and continuously monitored.

---

## 3. HTTP Access Traffic (1-minute interval) — *Visualization: Line Chart*

### SPL Used:
```bash
index=branch_office sourcetype=access_combined  
| timechart span=1m count
```

This panel uses the same logic as the previous time-based charts, again rolling events into 1-minute buckets using timechart.  
The only difference is:  
```sourcetype=access_combined``` - access_combined is the format used by the NGINX Splunk Add-on.

### Purpose:
This provides a quick visual check that synthetic HTTP traffic from the branch office (generated by the cron job) is being ingested correctly.

---

## 4. Top HTTP Request Paths (Top 10) — *Visualization: Table*

### SPL Used:
```bash
index=branch_office sourcetype=access_combined  
| stats count by uri_path  
| sort - count  
| head 10
```

```| stats count by uri_path```  
- stats groups events together  
- count tells Splunk to count how many requests belong to each value  
- uri_path is the field extracted by the NGINX Splunk add-on (e.g., /, /no-such-page)  
Result: one row per unique path with a request count.

```| sort - count``` - means descending order. Highest-traffic paths appear first.

```| head 10``` - Keeps only the top 10 most requested paths

### Purpose of This Panel
This panel shows which web pages (URL paths) are requested most often on the branch office NGINX server.  
In my current setup, that will mainly be the synthetic cron traffic (/ and /no-such-page), so this also doubles as a sanity check that the cron job is still hitting the expected paths.

---

## 5. Top HTTP Client IPs (Panel 5) — *Visualization: Table*

### SPL Used:
```bash
index=branch_office sourcetype=access_combined  
| stats count by clientip  
| sort - count  
| head 10
```

Instead of grouping by request path (uri_path) like the previous panel, this one groups by clientip, which is the field extracted from the access logs that represents the source IP address making the HTTP request.  
```| stats count by clientip``` - returns how many requests each client sent

### Purpose of This Panel:
This panel shows which devices are hitting the branch office web server the most.  
My cron job generates hits locally from 127.0.0.1. Occasional manual browser visits come from the MacBook or other devices. Splunk records each unique source IP.
So this panel effectively shows the top source client devices generating HTTP traffic into the branch-office NGINX service.

---

## 6. Top HTTP Status Codes — *Visualization: Table*

### SPL Used:
```bash
index=branch_office sourcetype=access_combined  
| stats count by status  
| sort - count  
| head 10
```

This panel groups by the field status, which is the HTTP response code returned by NGINX (e.g., 200, 404, 500).

```| stats count by status``` - shows how many requests resulted in each status code.  
Sorted and trimmed to the top 10 just like previous panels.

### Purpose of This Panel:
This panel shows how the branch web server is responding:  
- 200 → normal  
- 404 → our synthetic “no-such-page” cron job  
- Anything else (500, 302, etc.) would stand out immediately

---

## 7. HTTP Methods Breakdown — *Visualization: Table*

### SPL Used:
```bash
index=branch_office sourcetype=access_combined  
| stats count by method  
| sort - count
```

This time I grouped by the method field (e.g., GET, POST, PUT, DELETE).  
```| stats count by method``` - shows how often each HTTP method is used.

### Purpose of This Panel:
This panel shows what kinds of HTTP operations are being performed against the branch web server.
Right now we only see GET because the synthetic cron jobs issue GET requests and the website itself has no forms or anything else that would generate POST/PUT/DELETE traffic.  
If someone manually hits the server with a POST request then we would see POST show up here even if the page cannot process it.

---

## 8. SMB Writers (by host) — *Visualization: Table*

### SPL Used:
```bash
index=branch_office sourcetype=smb_activity  
| stats count as writes by host  
| sort - writes
```

I grouped by the host field, which represents the hostname of the machine that wrote into the SMB share.  
```| stats count as writes by host``` – shows how many SMB write events each host generated. I renamed the count field to *writes* just for readability.

Sorted highest → lowest, same as the previous tables.

### Purpose of This Panel:
This panel shows which hosts are actively writing files into the branch office SMB share.  
Right now only the ThinkPad appears here because the synthetic cron job on the ThinkPad writes smb_activity.log every minute.  
If another machine mounted the share and wrote files, it would appear in this table as well.

---

## 9. Event Volume by Host — *Visualization: Bar Chart*

### SPL Used:
```bash
(index=endpoints OR index=branch_office)  
| stats count as events by host  
| sort - events
```

I queried both of my indexes instead of just branch_office, because this panel is meant to show log volume across every host in my entire Cyberlab.

```| stats count as events by host``` – counts how many events each host has produced (across all sourcetypes).  
I renamed the output field to *events* to keep the table cleaner.

Sorted highest → lowest as usual.

### Purpose of This Panel:
This panel shows which machines in my Cyberlab are generating the most log volume overall.  
This gives a quick at-a-glance view of which hosts are “noisiest” in terms of log generation.